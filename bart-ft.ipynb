{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:52:27.078684Z",
     "iopub.status.busy": "2024-06-08T17:52:27.078401Z",
     "iopub.status.idle": "2024-06-08T17:52:28.025988Z",
     "shell.execute_reply": "2024-06-08T17:52:28.024948Z",
     "shell.execute_reply.started": "2024-06-08T17:52:27.078658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: /opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info: No such file or directory\n",
      "rm: -rdf: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm /opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info -rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:52:28.031223Z",
     "iopub.status.busy": "2024-06-08T17:52:28.030929Z",
     "iopub.status.idle": "2024-06-08T17:52:40.367796Z",
     "shell.execute_reply": "2024-06-08T17:52:40.366875Z",
     "shell.execute_reply.started": "2024-06-08T17:52:28.031170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (2.3.1)\n",
      "Requirement already satisfied: nltk in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from nltk->rouge_score) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:52:40.369604Z",
     "iopub.status.busy": "2024-06-08T17:52:40.369270Z",
     "iopub.status.idle": "2024-06-08T17:52:52.880632Z",
     "shell.execute_reply": "2024-06-08T17:52:52.879648Z",
     "shell.execute_reply.started": "2024-06-08T17:52:40.369575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (0.34.4)\n",
      "Requirement already satisfied: packaging in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yujiafu/opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:52:52.883612Z",
     "iopub.status.busy": "2024-06-08T17:52:52.883280Z",
     "iopub.status.idle": "2024-06-08T17:53:00.340490Z",
     "shell.execute_reply": "2024-06-08T17:53:00.339681Z",
     "shell.execute_reply.started": "2024-06-08T17:52:52.883582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:00.342150Z",
     "iopub.status.busy": "2024-06-08T17:53:00.341614Z",
     "iopub.status.idle": "2024-06-08T17:53:00.409154Z",
     "shell.execute_reply": "2024-06-08T17:53:00.408182Z",
     "shell.execute_reply.started": "2024-06-08T17:53:00.342122Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preporcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:00.410632Z",
     "iopub.status.busy": "2024-06-08T17:53:00.410299Z",
     "iopub.status.idle": "2024-06-08T17:53:02.658730Z",
     "shell.execute_reply": "2024-06-08T17:53:02.657742Z",
     "shell.execute_reply.started": "2024-06-08T17:53:00.410607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8a259b86a8421f9b9c4ef794746cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348a48ecf48e40458ac76b7ca49bcadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.parquet:   0%|          | 0.00/323M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-11-22T19:49:30.619472Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x1075db1f0>), traceback: Some(<traceback object at 0x345958a80>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m download_files(\n\u001b[1;32m    630\u001b[0m     xet_download_info,\n\u001b[1;32m    631\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconnection_info\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m    632\u001b[0m     token_info\u001b[38;5;241m=\u001b[39m(connection_info\u001b[38;5;241m.\u001b[39maccess_token, connection_info\u001b[38;5;241m.\u001b[39mexpiration_unix_epoch),\n\u001b[1;32m    633\u001b[0m     token_refresher\u001b[38;5;241m=\u001b[39mtoken_refresher,\n\u001b[1;32m    634\u001b[0m     progress_updater\u001b[38;5;241m=\u001b[39m[progress_updater],\n\u001b[1;32m    635\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''@misc{alex2019multinews,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m    title={Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    author={Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    primaryClass={cs.CL}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m}'''\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m ds \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAwesome075/multi_news_parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/load.py:1412\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1412\u001b[0m builder_instance\u001b[38;5;241m.\u001b[39mdownload_and_prepare(\n\u001b[1;32m   1413\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[1;32m   1414\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[1;32m   1415\u001b[0m     verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[1;32m   1416\u001b[0m     num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m   1417\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   1418\u001b[0m )\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1422\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   1423\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/builder.py:894\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    893\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_and_prepare(\n\u001b[1;32m    895\u001b[0m     dl_manager\u001b[38;5;241m=\u001b[39mdl_manager,\n\u001b[1;32m    896\u001b[0m     verification_mode\u001b[38;5;241m=\u001b[39mverification_mode,\n\u001b[1;32m    897\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_split_kwargs,\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[1;32m    899\u001b[0m )\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/builder.py:948\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    946\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m    947\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 948\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_generators(dl_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msplit_generators_kwargs)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/packaged_modules/parquet/parquet.py:49\u001b[0m, in \u001b[0;36mParquet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one data file must be specified, but got data_files=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m dl_manager\u001b[38;5;241m.\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mextract_on_the_fly \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m data_files \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownload_and_extract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_files)\n\u001b[1;32m     50\u001b[0m splits \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split_name, files \u001b[38;5;129;01min\u001b[39;00m data_files\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/download/download_manager.py:326\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload(url_or_urls))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/download/download_manager.py:159\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 159\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m map_nested(\n\u001b[1;32m    160\u001b[0m         download_func,\n\u001b[1;32m    161\u001b[0m         url_or_urls,\n\u001b[1;32m    162\u001b[0m         map_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    163\u001b[0m         num_proc\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mnum_proc,\n\u001b[1;32m    164\u001b[0m         desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading data files\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    165\u001b[0m         batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    166\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/utils/py_utils.py:521\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    518\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    519\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    520\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 521\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    523\u001b[0m ]\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    525\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/utils/py_utils.py:408\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    405\u001b[0m         k: _single_map_nested((function, v, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m pbar\n\u001b[1;32m    406\u001b[0m     }\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [_single_map_nested((function, v, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m pbar]\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mapped\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/utils/py_utils.py:389\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     batched\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    388\u001b[0m ):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m function(batch)]\n\u001b[1;32m    391\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/download/download_manager.py:220\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_single(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/download/download_manager.py:229\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m cached_path(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    230\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[1;32m    231\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/datasets/utils/file_utils.py:177\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfFileSystem(\n\u001b[1;32m    168\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT, token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m    169\u001b[0m )\u001b[38;5;241m.\u001b[39mresolve_path(url_or_filename)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfApi(\n\u001b[1;32m    172\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT,\n\u001b[1;32m    173\u001b[0m         token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    174\u001b[0m         library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    175\u001b[0m         library_version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[1;32m    176\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39mget_datasets_user_agent(download_config\u001b[38;5;241m.\u001b[39muser_agent),\n\u001b[0;32m--> 177\u001b[0m     )\u001b[38;5;241m.\u001b[39mhf_hub_download(\n\u001b[1;32m    178\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mresolved_path\u001b[38;5;241m.\u001b[39mrepo_id,\n\u001b[1;32m    179\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mresolved_path\u001b[38;5;241m.\u001b[39mrepo_type,\n\u001b[1;32m    180\u001b[0m         revision\u001b[38;5;241m=\u001b[39mresolved_path\u001b[38;5;241m.\u001b[39mrevision,\n\u001b[1;32m    181\u001b[0m         filename\u001b[38;5;241m=\u001b[39mresolved_path\u001b[38;5;241m.\u001b[39mpath_in_repo,\n\u001b[1;32m    182\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mforce_download,\n\u001b[1;32m    183\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[1;32m    187\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[1;32m    188\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[1;32m    189\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[1;32m    190\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/hf_api.py:5528\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5525\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5526\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hf_hub_download(\n\u001b[1;32m   5529\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   5530\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   5531\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   5532\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   5533\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   5534\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m   5535\u001b[0m     library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary_name,\n\u001b[1;32m   5536\u001b[0m     library_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary_version,\n\u001b[1;32m   5537\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   5538\u001b[0m     local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   5539\u001b[0m     local_dir_use_symlinks\u001b[38;5;241m=\u001b[39mlocal_dir_use_symlinks,\n\u001b[1;32m   5540\u001b[0m     user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_agent,\n\u001b[1;32m   5541\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   5542\u001b[0m     force_filename\u001b[38;5;241m=\u001b[39mforce_filename,\n\u001b[1;32m   5543\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   5544\u001b[0m     etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   5545\u001b[0m     resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   5546\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   5547\u001b[0m     headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m   5548\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   5549\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1015\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1016\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1017\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1020\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1021\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m   1022\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1023\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1026\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1027\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     _download_to_tmp_and_move(\n\u001b[1;32m   1172\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mPath(blob_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.incomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1173\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mPath(blob_path),\n\u001b[1;32m   1174\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[1;32m   1175\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1176\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1177\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1178\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1179\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1180\u001b[0m         etag\u001b[38;5;241m=\u001b[39metag,\n\u001b[1;32m   1181\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[1;32m   1182\u001b[0m     )\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     xet_get(\n\u001b[1;32m   1724\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mincomplete_path,\n\u001b[1;32m   1725\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[1;32m   1726\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1727\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1728\u001b[0m         displayed_filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1729\u001b[0m     )\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:624\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    613\u001b[0m     displayed_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[38;5;241m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(â€¦)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m progress_cm \u001b[38;5;241m=\u001b[39m _get_progress_bar_context(\n\u001b[1;32m    616\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdisplayed_filename,\n\u001b[1;32m    617\u001b[0m     log_level\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m     _tqdm_bar\u001b[38;5;241m=\u001b[39m_tqdm_bar,\n\u001b[1;32m    622\u001b[0m )\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    627\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:1138\u001b[0m, in \u001b[0;36mtqdm.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 1138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''@misc{alex2019multinews,\n",
    "    title={Multi-News: a Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model},\n",
    "    author={Alexander R. Fabbri and Irene Li and Tianwei She and Suyi Li and Dragomir R. Radev},\n",
    "    year={2019},\n",
    "    eprint={1906.01749},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CL}\n",
    "}'''\n",
    "\n",
    "\n",
    "ds = load_dataset(\"Awesome075/multi_news_parquet\", split=\"train\") # This is the same to original Multi-News dataset, it is repackaged to be loaded in the easy way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:02.660278Z",
     "iopub.status.busy": "2024-06-08T17:53:02.659936Z",
     "iopub.status.idle": "2024-06-08T17:53:02.826203Z",
     "shell.execute_reply": "2024-06-08T17:53:02.825366Z",
     "shell.execute_reply.started": "2024-06-08T17:53:02.660246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example for a summarization model:\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m model     \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/bart-large-cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Then you can tokenize text:\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1093\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1093\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m   1094\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1095\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1332\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1329\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1330\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1332\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1333\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1334\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/transformers/configuration_utils.py:662\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/transformers/configuration_utils.py:721\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    722\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    723\u001b[0m         configuration_file,\n\u001b[1;32m    724\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    725\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    726\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    727\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    728\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    729\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    730\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    731\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    732\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m    733\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    265\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    266\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    268\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    323\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m         hf_hub_download(\n\u001b[1;32m    480\u001b[0m             path_or_repo_id,\n\u001b[1;32m    481\u001b[0m             filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    482\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    483\u001b[0m             repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    484\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    485\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    486\u001b[0m             user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    487\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    488\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    489\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    490\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    491\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    492\u001b[0m         )\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         snapshot_download(\n\u001b[1;32m    495\u001b[0m             path_or_repo_id,\n\u001b[1;32m    496\u001b[0m             allow_patterns\u001b[38;5;241m=\u001b[39mfull_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    506\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1015\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1016\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1017\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1020\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1021\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m   1022\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1023\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1026\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1027\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     _download_to_tmp_and_move(\n\u001b[1;32m   1172\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mPath(blob_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.incomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1173\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mPath(blob_path),\n\u001b[1;32m   1174\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[1;32m   1175\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1176\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1177\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1178\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1179\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1180\u001b[0m         etag\u001b[38;5;241m=\u001b[39metag,\n\u001b[1;32m   1181\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[1;32m   1182\u001b[0m     )\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:1738\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n\u001b[1;32m   1732\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1733\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo, but the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf_xet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m package is not installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1734\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to regular HTTP download. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1735\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1736\u001b[0m             )\n\u001b[0;32m-> 1738\u001b[0m         http_get(\n\u001b[1;32m   1739\u001b[0m             url_to_download,\n\u001b[1;32m   1740\u001b[0m             f,\n\u001b[1;32m   1741\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1742\u001b[0m             resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1743\u001b[0m             headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1744\u001b[0m             expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1745\u001b[0m         )\n\u001b[1;32m   1747\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1748\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/file_download.py:451\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    444\u001b[0m     displayed_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(â€¦)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m40\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m consistency_error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsistency check failed: file should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but has size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;124mactual_size\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis is usually due to network issues while downloading the file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please retry with `force_download=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m )\n\u001b[0;32m--> 451\u001b[0m progress_cm \u001b[38;5;241m=\u001b[39m _get_progress_bar_context(\n\u001b[1;32m    452\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdisplayed_filename,\n\u001b[1;32m    453\u001b[0m     log_level\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel(),\n\u001b[1;32m    454\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[1;32m    455\u001b[0m     initial\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m    456\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuggingface_hub.http_get\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    457\u001b[0m     _tqdm_bar\u001b[38;5;241m=\u001b[39m_tqdm_bar,\n\u001b[1;32m    458\u001b[0m )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hf_transfer \u001b[38;5;129;01mand\u001b[39;00m total \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m total \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m constants\u001b[38;5;241m.\u001b[39mDOWNLOAD_CHUNK_SIZE:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/tqdm.py:299\u001b[0m, in \u001b[0;36m_get_progress_bar_context\u001b[0;34m(desc, log_level, total, initial, unit, unit_scale, name, _tqdm_bar)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nullcontext(_tqdm_bar)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# ^ `contextlib.nullcontext` mimics a context manager that does nothing\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;66;03m#   Makes it easier to use the same code path for both cases but in the later\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;66;03m#   case, the progress bar is not closed when exiting the context manager.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tqdm(\n\u001b[1;32m    300\u001b[0m     unit\u001b[38;5;241m=\u001b[39munit,\n\u001b[1;32m    301\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39munit_scale,\n\u001b[1;32m    302\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[1;32m    303\u001b[0m     initial\u001b[38;5;241m=\u001b[39minitial,\n\u001b[1;32m    304\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    305\u001b[0m     disable\u001b[38;5;241m=\u001b[39mis_tqdm_disabled(log_level\u001b[38;5;241m=\u001b[39mlog_level),\n\u001b[1;32m    306\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    307\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:665\u001b[0m, in \u001b[0;36mtqdm.__new__\u001b[0;34m(cls, *_, **__)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__):\n\u001b[1;32m    664\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_lock():  \u001b[38;5;66;03m# also constructs lock if non-existent\u001b[39;00m\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_instances\u001b[38;5;241m.\u001b[39madd(instance)\n\u001b[1;32m    667\u001b[0m         \u001b[38;5;66;03m# create monitoring thread\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:111\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.12/site-packages/tqdm/std.py:104\u001b[0m, in \u001b[0;36mTqdmDefaultWriteLock.acquire\u001b[0;34m(self, *a, **k)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk):\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocks:\n\u001b[0;32m--> 104\u001b[0m         lock\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mk)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Example for a summarization model:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Then you can tokenize text:\n",
    "inputs = tokenizer(\n",
    "    \"Here is the document you want to summarize â€¦\",\n",
    "    max_length=1024,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "# And generate summary:\n",
    "outputs = model.generate(**inputs)\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:02.828108Z",
     "iopub.status.busy": "2024-06-08T17:53:02.827745Z",
     "iopub.status.idle": "2024-06-08T17:53:02.833641Z",
     "shell.execute_reply": "2024-06-08T17:53:02.832554Z",
     "shell.execute_reply.started": "2024-06-08T17:53:02.828075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples['text'], max_length=1024, truncation=True\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples['summary'], max_length=128, truncation=True\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:02.835082Z",
     "iopub.status.busy": "2024-06-08T17:53:02.834796Z",
     "iopub.status.idle": "2024-06-08T17:53:07.206541Z",
     "shell.execute_reply": "2024-06-08T17:53:07.205667Z",
     "shell.execute_reply.started": "2024-06-08T17:53:02.835058Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5649f3977548d3996a08c88b00fdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f333be03c7247c7aaea125c18662ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:07.208158Z",
     "iopub.status.busy": "2024-06-08T17:53:07.207799Z",
     "iopub.status.idle": "2024-06-08T17:53:07.631800Z",
     "shell.execute_reply": "2024-06-08T17:53:07.630821Z",
     "shell.execute_reply.started": "2024-06-08T17:53:07.208126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "metric = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:07.633442Z",
     "iopub.status.busy": "2024-06-08T17:53:07.633067Z",
     "iopub.status.idle": "2024-06-08T17:53:07.641246Z",
     "shell.execute_reply": "2024-06-08T17:53:07.640243Z",
     "shell.execute_reply.started": "2024-06-08T17:53:07.633408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:07.643370Z",
     "iopub.status.busy": "2024-06-08T17:53:07.642569Z",
     "iopub.status.idle": "2024-06-08T17:53:08.264637Z",
     "shell.execute_reply": "2024-06-08T17:53:08.263695Z",
     "shell.execute_reply.started": "2024-06-08T17:53:07.643337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForSeq2SeqLM.from_pretrained('ainize/bart-base-cnn')\n",
    "# Batching function\n",
    "data_collator = transformers.DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:08.268186Z",
     "iopub.status.busy": "2024-06-08T17:53:08.267900Z",
     "iopub.status.idle": "2024-06-08T17:53:08.340977Z",
     "shell.execute_reply": "2024-06-08T17:53:08.340069Z",
     "shell.execute_reply.started": "2024-06-08T17:53:08.268161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define arguments of the finetuning\n",
    "training_args = transformers.Seq2SeqTrainingArguments(\n",
    "    output_dir='./bart_finetuning_results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  # batch size for train\n",
    "    per_device_eval_batch_size=8,  # batch size for eval\n",
    "    weight_decay=.01,\n",
    "    save_total_limit=3,  # num of checkpoints to save \n",
    "    num_train_epochs=2,\n",
    "    fp16=True,\n",
    "    predict_with_generate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:08.342491Z",
     "iopub.status.busy": "2024-06-08T17:53:08.342180Z",
     "iopub.status.idle": "2024-06-08T17:53:09.196857Z",
     "shell.execute_reply": "2024-06-08T17:53:09.195866Z",
     "shell.execute_reply.started": "2024-06-08T17:53:08.342465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = transformers.Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum['train'],\n",
    "    eval_dataset=tokenized_billsum['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:53:09.198464Z",
     "iopub.status.busy": "2024-06-08T17:53:09.198058Z",
     "iopub.status.idle": "2024-06-08T17:57:32.751002Z",
     "shell.execute_reply": "2024-06-08T17:57:32.750144Z",
     "shell.execute_reply.started": "2024-06-08T17:53:09.198426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvir\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240608_175310-gvbn9w5m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/svir/huggingface/runs/gvbn9w5m' target=\"_blank\">./bart_finetuning_results</a></strong> to <a href='https://wandb.ai/svir/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svir/huggingface' target=\"_blank\">https://wandb.ai/svir/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svir/huggingface/runs/gvbn9w5m' target=\"_blank\">https://wandb.ai/svir/huggingface/runs/gvbn9w5m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 04:01, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.117500</td>\n",
       "      <td>0.178640</td>\n",
       "      <td>0.098246</td>\n",
       "      <td>0.159710</td>\n",
       "      <td>0.169381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.065461</td>\n",
       "      <td>0.182595</td>\n",
       "      <td>0.101807</td>\n",
       "      <td>0.163663</td>\n",
       "      <td>0.172274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=2.3062035696847096, metrics={'train_runtime': 263.2571, 'train_samples_per_second': 8.456, 'train_steps_per_second': 0.532, 'total_flos': 1357273356042240.0, 'train_loss': 2.3062035696847096, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:57:32.752363Z",
     "iopub.status.busy": "2024-06-08T17:57:32.752078Z",
     "iopub.status.idle": "2024-06-08T17:57:32.761877Z",
     "shell.execute_reply": "2024-06-08T17:57:32.761080Z",
     "shell.execute_reply.started": "2024-06-08T17:57:32.752338Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The people of the State of California do enact as follows:\n",
      "\n",
      "\n",
      "SECTION 1.\n",
      "Section 1464 of the Penal Code is amended to read:\n",
      "1464.\n",
      "(a) (1) Subject to Chapter 12 (commencing with Section 76000) of Title 8 of the Government Code, and except as otherwise provided in this section, there shall be levied a state penalty in the amount of ten dollars ($10) for every ten dollars ($10), or part of ten dollars ($10), upon every fine, penalty, or forfeiture imposed and collected by the courts for all criminal offenses, including all offenses, except parking offenses as defined in subdivision (i) of Section 1463, involving a violation of a section of the Vehicle Code or any local ordinance adopted pursuant to the Vehicle Code.\n",
      "(2) Any bail schedule adopted pursuant to Section 1269b or bail schedule adopted by the Judicial Council pursuant to Section 40310 of the Vehicle Code may include the necessary amount to pay the penalties established by this section and Chapter 12 (commencing with Section 76000) of Title 8 of the Government Code, and the surcharge authorized by Section 1465.7, for all matters where a personal appearance is not mandatory and the bail is posted primarily to guarantee payment of the fine.\n",
      "(3) The penalty imposed by this section does not apply to the following:\n",
      "(A) Any restitution fine.\n",
      "(B) Any penalty authorized by Chapter 12 (commencing with Section 76000) of Title 8 of the Government Code.\n",
      "(C) Any parking offense subject to Article 3 (commencing with Section 40200) of Chapter 1 of Division 17 of the Vehicle Code.\n",
      "(D) The state surcharge authorized by Section 1465.7.\n",
      "(b) Where multiple offenses are involved, the state penalty shall be based upon the total fine or bail for each case. When a fine is suspended, in whole or in part, the state penalty shall be reduced in proportion to the suspension.\n",
      "(c) When any deposited bail is made for an offense to which this section applies, and for which a court appearance is not mandatory, the person making the deposit shall also deposit a sufficient amount to include the state penalty prescribed by this section for forfeited bail. If bail is returned, the state penalty paid thereon pursuant to this section shall also be returned.\n",
      "(d) In any case where a person convicted of any offense, to which this section applies, is in prison until the fine is satisfied, the judge may waive all or any part of the state penalty, the payment of which would work a hardship on the person convicted or his or her immediate family.\n",
      "(e) After a determination by the court of the amount due, the clerk of the court shall collect the penalty and transmit it to the county treasury. The portion thereof attributable to Chapter 12 (commencing with Section 76000) of Title 8 of the Government Code shall be deposited in the appropriate county fund and 70 percent of the balance shall then be transmitted to the State Treasury, to be deposited in the State Penalty Fund, which is hereby created, and 30 percent to remain on deposit in the county general fund. The transmission to the State Treasury shall be carried out in the same manner as fines collected for the state by a county.\n",
      "(f) The moneys so deposited in the State Penalty Fund shall be distributed as follows:\n",
      "(1) Once a month there shall be transferred into the Fish and Game Preservation Fund an amount equal to 0.33 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month, except that the total amount shall not be less than the state penalty levied on fines or forfeitures for violation of state laws relating to the protection or propagation of fish and game. These moneys shall be used for the education or training of department employees which fulfills a need consistent with the objectives of the Department of Fish and\n",
      "Game.\n",
      "Wildlife.\n",
      "(2) Once a month there shall be transferred into the Restitution Fund an amount equal to 32.02 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month. Those funds shall be made available in accordance with Section 13967 of the Government Code.\n",
      "(3) Once a month there shall be transferred into the Peace Officersâ€™ Training Fund an amount equal to 23.99 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month.\n",
      "(4) Once a month there shall be transferred into the\n",
      "Driver Training Penalty Assessment\n",
      "Body-worn Camera\n",
      "Fund an amount equal to 25.70 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month.\n",
      "(5) Once a month there shall be transferred into the Corrections Training Fund an amount equal to 7.88 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month. Money in the Corrections Training Fund is not continuously appropriated and shall be appropriated in the Budget Act.\n",
      "(6) Once a month there shall be transferred into the Local Public Prosecutors and Public Defenders Training Fund established pursuant to Section 11503 an amount equal to 0.78 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month. The amount so transferred shall not exceed the sum of eight hundred fifty thousand dollars ($850,000) in any fiscal year. The remainder in excess of eight hundred fifty thousand dollars ($850,000) shall be transferred to the Restitution Fund.\n",
      "(7) Once a month there shall be transferred into the Victim-Witness Assistance Fund an amount equal to 8.64 percent of the state penalty funds deposited in the State Penalty Fund during the preceding month.\n",
      "(8) (A) Once a month there shall be transferred into the Traumatic Brain Injury Fund, created pursuant to Section 4358 of the Welfare and Institutions Code, an amount equal to 0.66 percent of the state penalty funds deposited into the State Penalty Fund during the preceding month. However, the amount of funds transferred into the Traumatic Brain Injury Fund for the 1996â€“97 fiscal year shall not exceed the amount of five hundred thousand dollars ($500,000). Thereafter, funds shall be transferred pursuant to the requirements of this section. Notwithstanding any other provision of law, the funds transferred into the Traumatic Brain Injury Fund for the 1997â€“98, 1998â€“99, and 1999â€“2000 fiscal years, may be expended by the State Department of Mental Health, in the current fiscal year or a subsequent fiscal year, to provide additional funding to the existing projects funded by the Traumatic Brain Injury Fund, to support new projects, or to do both.\n",
      "(B) Any moneys deposited in the State Penalty Fund attributable to the assessments made pursuant to subdivision (i) of Section 27315 of the Vehicle Code on or after the date that Chapter 6.6 (commencing with Section 5564) of Part 1 of Division 5 of the Welfare and Institutions Code is repealed shall be utilized in accordance with paragraphs (1) to (8), inclusive, of this subdivision.\n",
      "SEC. 2.\n",
      "Title 14 (commencing with Section 14400) is added to Part 4 of the Penal Code, to read:\n",
      "TITLE 14. Body-Worn Camera Grant Program for Local Law Enforcement\n",
      "14400.\n",
      "The Board of State and Community Corrections shall develop a grant program for the purpose of making funds available to local law enforcement entities to purchase body-worn cameras and related data storage and equipment, and to hire personnel necessary to operate a local body-worn camera program.\n",
      "14402.\n",
      "The Body-worn Camera Fund is hereby created. Notwithstanding Section 13340 of the Government Code, all moneys in the fund are continuously appropriated to the Board of State and Community Corrections for the purposes of Section 14400.\n",
      "14404.\n",
      "If federal funds become available for the purpose of purchasing body-worn cameras and related equipment for local law enforcement, the Board of State and Community Corrections shall adjust the grant program to maximize state and local competitiveness in obtaining federal funds, and the board shall either apply for federal funds on behalf of a local law enforcement agency, or reimburse a local law enforcement agency that has expended funds for federal funds purposes.\n",
      "SECTION 1.\n",
      "Section 566 of the\n",
      "Penal Code\n",
      "is amended to read:\n",
      "566.\n",
      "It is a felony, punishable by a fine not exceeding one thousand five hundred dollars ($1,500), or by imprisonment pursuant to subdivision (h) of Section 1170, or both, for an unauthorized person to possess or use, or to obliterate or destroy the brand registration upon, containers, including milk cases, cabinets, or other dairy equipment, which have a value in excess of nine hundred fifty dollars ($950), when the containers, cabinets, or other dairy equipment are marked with a brand that is registered pursuant to Chapter 10 (commencing with Section 34501) of Part 1 of Division 15 of the Food and Agricultural Code. For purposes of this section, â€œunauthorized personâ€ has the same meaning as defined in Section 34564 of the Food and Agricultural Code.\n"
     ]
    }
   ],
   "source": [
    "text_example = billsum['test']['text'][42]\n",
    "print(text_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:57:32.763439Z",
     "iopub.status.busy": "2024-06-08T17:57:32.763108Z",
     "iopub.status.idle": "2024-06-08T17:57:32.781202Z",
     "shell.execute_reply": "2024-06-08T17:57:32.780366Z",
     "shell.execute_reply.started": "2024-06-08T17:57:32.763405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(\n",
    "    text_example,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=1024,\n",
    "    truncation=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:57:32.782581Z",
     "iopub.status.busy": "2024-06-08T17:57:32.782260Z",
     "iopub.status.idle": "2024-06-08T17:57:32.792084Z",
     "shell.execute_reply": "2024-06-08T17:57:32.791124Z",
     "shell.execute_reply.started": "2024-06-08T17:57:32.782559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:57:32.793654Z",
     "iopub.status.busy": "2024-06-08T17:57:32.793296Z",
     "iopub.status.idle": "2024-06-08T17:57:34.045453Z",
     "shell.execute_reply": "2024-06-08T17:57:34.044257Z",
     "shell.execute_reply.started": "2024-06-08T17:57:32.793620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summary_text_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    bos_token_id=model.config.bos_token_id,\n",
    "    eos_token_id=model.config.eos_token_id,\n",
    "    max_length=142,\n",
    "    min_length=56,\n",
    "    num_beams=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T17:57:34.047772Z",
     "iopub.status.busy": "2024-06-08T17:57:34.047393Z",
     "iopub.status.idle": "2024-06-08T17:57:34.054327Z",
     "shell.execute_reply": "2024-06-08T17:57:34.053448Z",
     "shell.execute_reply.started": "2024-06-08T17:57:34.047740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing law provides for the imposition of a state penalty upon every fine, penalty, or forfeiture imposed and collected by the courts for all criminal offenses, including all offenses, except parking offenses as defined. Existing law also provides that the penalty imposed by this bill is based upon the total fine or bail for each case, except as otherwise provided, and that the state penalty shall be based upon a bail schedule adopted by the Judicial Council, as specified.\n",
      "This bill would require the clerk of the court to collect the penalty and transmit it to the county treasury.\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(summary_text_ids[0], skip_special_tokens=True)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30716,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
